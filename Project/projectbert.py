# -*- coding: utf-8 -*-
"""ProjectBERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KL7KmSM1MBexQ8Oc_gjvBvWBV1VwhWO9
"""

import numpy as np
import pandas as pd
 
import matplotlib.pyplot as plt
import seaborn as sns
 
import warnings
import pickle

from google.colab import drive
 
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My\ Drive/NLP_Project

with open(r"processed_english.pkl", "rb") as input_file:
    data = pickle.load(input_file)

data.shape

data = data[:1000]
train = data[:5000]
test = data[5000:]

pd.options.display.max_colwidth = 350
train[train['sentiment'] == "negative"].head(10)
train[train['sentiment'] == "positive"].head(10)

!pip install -qq transformers

# Commented out IPython magic to ensure Python compatibility.
import transformers
from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup
import torch
import numpy as np
import pandas as pd
import seaborn as sns
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib import rc
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from collections import defaultdict
from textwrap import wrap
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
# %matplotlib inline
# %config InlineBackend.figure_format='retina'
sns.set(style='whitegrid', palette='muted', font_scale=1.2)
HAPPY_COLORS_PALETTE = ["#01BEFE", "#FFDD00", "#FF7D00", "#FF006D", "#ADFF02", "#8F00FF"]
sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))
rcParams['figure.figsize'] = 12, 8
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

'''
Bert pre-trained model used
'''

PRE_TRAINED_MODEL_NAME = 'bert-base-cased'

'''
tokeniser to tokenize the data
'''

tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)

sample_txt = 'rt i of pakistan team to offer 5 hang on and go home ðŸ˜Ÿ'

'''
tokeniser example
'''


tokens = tokenizer.tokenize(sample_txt)
token_ids = tokenizer.convert_tokens_to_ids(tokens)
print(f' Sentence: {sample_txt}')
print(f'   Tokens: {tokens}')
print(f'Token IDs: {token_ids}')

'''
encoding the whole dataser
'''

encoding = tokenizer.encode_plus(
  sample_txt,
  add_special_tokens=True, # Add '[CLS]' and '[SEP]'
  return_token_type_ids=False,
  padding=True,
  return_attention_mask=True,
  return_tensors='pt',  # Return PyTorch tensors
)

print(data['sentence_eng'][201])

'''
calculating len of the dataset
'''

token_lens = []
i=0
for txt in data.sentence_eng:
  i +=1
  #if(i%100==0):
  print(txt)
  print(i)
  tokens = tokenizer.encode(txt, max_length=512)
  token_lens.append(len(tokens))

'''
plotting length of sentences wrt to tokens
'''
sns.distplot(token_lens)
plt.xlim([0, 256])
plt.xlabel('Token count')

print(max(token_lens))

'''
length of the mebeddings
'''

MAX_LEN = 60

'''
sentiment to numerical value
'''

def to_sentiment(sentiment):
  if sentiment == 'positive':
    return 2
  elif sentiment == 'neutral':
    return 1
  else:
    return 0
data['score'] = data.sentiment.apply(to_sentiment)
class_names = ['negative', 'neutral', 'positive']

data.head()

'''
to encode the data
'''

class TwitterDataset(Dataset):
  def __init__(self, reviews, targets, tokenizer, max_len):
    self.reviews = reviews
    self.targets = targets
    self.tokenizer = tokenizer
    self.max_len = max_len
  def __len__(self):
    return len(self.reviews)
  def __getitem__(self, item):
    review = str(self.reviews[item])
    target = self.targets[item]
    encoding = self.tokenizer.encode_plus(
      review,
      add_special_tokens=True,
      max_length=self.max_len,
      return_token_type_ids=False,
      pad_to_max_length=True,
      return_attention_mask=True,
      return_tensors='pt',
    )
    return {
      'review_text': review,
      'input_ids': encoding['input_ids'].flatten(),
      'attention_mask': encoding['attention_mask'].flatten(),
      'targets': torch.tensor(target, dtype=torch.long)
    }

'''
split to train, test and validation
'''
df_train, df_test = train_test_split(
  data,
  test_size=0.3,
  random_state=RANDOM_SEED
)
df_val, df_test = train_test_split(
  df_test,
  test_size=0.35,
  random_state=RANDOM_SEED
)

'''
Encoding of train, test and validation dataset
'''


def create_data_loader(df, tokenizer, max_len, batch_size):
  ds = TwitterDataset(
    reviews=df.sentence_eng.to_numpy(),
    targets=df.score.to_numpy(),
    tokenizer=tokenizer,
    max_len=max_len
  )
  return DataLoader(
    ds,
    batch_size=batch_size,
    num_workers=4
  )

BATCH_SIZE = 16
train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)
val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)
test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)

bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)

'''
input to the bert model
'''

class SentimentClassifier(nn.Module):
  def __init__(self, n_classes):
    super(SentimentClassifier, self).__init__()
    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)
    self.drop = nn.Dropout(p=0.3)
    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)
  def forward(self, input_ids, attention_mask):
    _, pooled_output = self.bert(
      input_ids=input_ids,
      attention_mask=attention_mask,
      return_dict= False
    )
    output = self.drop(pooled_output)
    return self.out(output)

'''
Initialising the model
'''

model = SentimentClassifier(len(class_names))
model = model.to(device)

EPOCHS = 10
'''
regularization and optimization
'''

optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)
total_steps = len(train_data_loader) * EPOCHS
scheduler = get_linear_schedule_with_warmup(
  optimizer,
  num_warmup_steps=0,
  num_training_steps=total_steps
)
loss_fn = nn.CrossEntropyLoss().to(device)

'''
Training of the model
'''

def train_epoch(
  model,
  data_loader,
  loss_fn,
  optimizer,
  device,
  scheduler,
  n_examples
):
  model = model.train()
  losses = []
  correct_predictions = 0
  for d in data_loader:
    input_ids = d["input_ids"].to(device)
    attention_mask = d["attention_mask"].to(device)
    targets = d["targets"].to(device)
    outputs = model(
      input_ids=input_ids,
      attention_mask=attention_mask
    )
    _, preds = torch.max(outputs, dim=1)
    loss = loss_fn(outputs, targets)
    correct_predictions += torch.sum(preds == targets)
    losses.append(loss.item())
    loss.backward()
    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
    optimizer.step()
    scheduler.step()
    optimizer.zero_grad()
  return correct_predictions.double() / n_examples, np.mean(losses)

'''
evaluating the model
'''

def eval_model(model, data_loader, loss_fn, device, n_examples):
  model = model.eval()
  losses = []
  correct_predictions = 0
  with torch.no_grad():
    for d in data_loader:
      input_ids = d["input_ids"].to(device)
      attention_mask = d["attention_mask"].to(device)
      targets = d["targets"].to(device)
      outputs = model(
        input_ids=input_ids,
        attention_mask=attention_mask
      )
      _, preds = torch.max(outputs, dim=1)
      loss = loss_fn(outputs, targets)
      correct_predictions += torch.sum(preds == targets)
      losses.append(loss.item())
  return correct_predictions.double() / n_examples, np.mean(losses)

EPOCHS = 5

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history = defaultdict(list)
# best_accuracy = 0
# 
# '''
# Training the model for every epoch
# '''
# for epoch in range(EPOCHS):
#   print(f'Epoch {epoch + 1}/{EPOCHS}')
#   print('-' * 10)
#   train_acc, train_loss = train_epoch(
#     model,
#     train_data_loader,
#     loss_fn,
#     optimizer,
#     device,
#     scheduler,
#     len(df_train)
#   )
#   print(f'Train loss {train_loss} accuracy {train_acc}')
#   val_acc, val_loss = eval_model(
#     model,
#     val_data_loader,
#     loss_fn,
#     device,
#     len(df_val)
#   )
#   print(f'Val   loss {val_loss} accuracy {val_acc}')
#   print()
#   history['train_acc'].append(train_acc)
#   history['train_loss'].append(train_loss)
#   history['val_acc'].append(val_acc)
#   history['val_loss'].append(val_loss)
#   if val_acc > best_accuracy:
#     torch.save(model.state_dict(), 'best_model_state.bin')
#     best_accuracy = val_acc

'''
Plotting the training and validation accuracy
'''

plt.plot(history['train_acc'], label='train accuracy')
plt.plot(history['val_acc'], label='validation accuracy')
plt.title('Training history')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.ylim([0, 1])

'''
Evaluating the model on test data
'''

test_acc, _ = eval_model(
  model,
  test_data_loader,
  loss_fn,
  device,
  len(df_test)
)
test_acc.item()

'''
Prediction conversion
'''

def get_predictions(model, data_loader):
  model = model.eval()
  review_texts = []
  predictions = []
  prediction_probs = []
  real_values = []
  with torch.no_grad():
    for d in data_loader:
      texts = d["review_text"]
      input_ids = d["input_ids"].to(device)
      attention_mask = d["attention_mask"].to(device)
      targets = d["targets"].to(device)
      outputs = model(
        input_ids=input_ids,
        attention_mask=attention_mask
      )
      _, preds = torch.max(outputs, dim=1)
      review_texts.extend(texts)
      predictions.extend(preds)
      prediction_probs.extend(outputs)
      real_values.extend(targets)
  predictions = torch.stack(predictions).cpu()
  prediction_probs = torch.stack(prediction_probs).cpu()
  real_values = torch.stack(real_values).cpu()
  return review_texts, predictions, prediction_probs, real_values

y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(
  model,
  test_data_loader
)

'''
To print the classification report
'''

print(classification_report(y_test, y_pred, target_names=['negative', 'positive','neutral' ]))

'''
Printing the confusion matrix
'''

def show_confusion_matrix(confusion_matrix):
  hmap = sns.heatmap(confusion_matrix, annot=True, fmt="d", cmap="Blues")
  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')
  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')
  plt.ylabel('True sentiment')
  plt.xlabel('Predicted sentiment');
cm = confusion_matrix(y_test, y_pred)
df_cm = pd.DataFrame(cm, index=['neagtive','positive','neutral'], columns=['neagtive','positive','neutral'])
show_confusion_matrix(df_cm)

print(y_review_texts)
print(y_pred_probs)

df_dump = pd.DataFrame(list(zip(y_review_texts, y_test.tolist(), y_pred.tolist())), columns = ['text', 'sent_actual', 'sent_pred'])

'''
Dumping the output for error analysis
'''

with open(r"BERTOP.pkl", "wb") as output_file:
    pickle.dump(df_dump, output_file)

'''

TO test on raw data
'''

review_text = "I hate this movie. this is bullshit"

encoded_review = tokenizer.encode_plus(
  review_text,
  max_length=MAX_LEN,
  add_special_tokens=True,
  return_token_type_ids=False,
  pad_to_max_length=True,
  return_attention_mask=True,
  return_tensors='pt',
)

class_names = {0:'negative', 1:'neutral', 2:'positive'}

input_ids = encoded_review['input_ids'].to(device)
attention_mask = encoded_review['attention_mask'].to(device)
output = model(input_ids, attention_mask)
_, prediction = torch.max(output, dim=1)
print(f'Review text: {review_text}')
print(f'Sentiment  : {class_names[int(prediction.tolist()[0])]}')

