{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2000 to /home/ankita/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import conll2000\n",
    "nltk.download(\"conll2000\")\n",
    "import nltk.stem.porter \n",
    "from nltk.classify import MaxentClassifier\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from nltk import ConfusionMatrix\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Suffix nomenclature(not used but helpful in testing for extra features)\n",
    "'''\n",
    "NOUN_SUFFIX =['eer','er','ion','ity','ment','ness','or','tion','ship','th']\n",
    "ADJ_SUFFIX = ['able','ible,','al','ant','ary','ful','ic','ious','ous','ive','less','y']\n",
    "VERB_SUFFIX = ['ed','en','er','ing','ise','ize']\n",
    "ADVERB_SUFFIX = ['ly','ward','wise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_suffix(word,suffix):\n",
    "    '''\n",
    "    Utility function to check if a string in the array passed is a suffix or not\n",
    "    '''\n",
    "    val = False\n",
    "    for s in suffix:\n",
    "        val = val or word.endswith(s)\n",
    "    return val\n",
    "\n",
    "def output_pos_suffix(word):\n",
    "    '''\n",
    "    Output predicted part of speech based on suffixes\n",
    "    '''\n",
    "    if check_suffix(word,NOUN_SUFFIX):\n",
    "        return \"Noun\"\n",
    "    elif check_suffix(word,ADJ_SUFFIX):\n",
    "        return \"Adj\"\n",
    "    elif check_suffix(word,VERB_SUFFIX):\n",
    "        return \"Verb\"\n",
    "    elif check_suffix(word,ADVERB_SUFFIX):\n",
    "        return \"Adverb\"\n",
    "    else: \n",
    "        return \"None\"\n",
    "    \n",
    "    \n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def return_affix(word):\n",
    "    word = word.lower()\n",
    "    stem_word = stemmer.stem(word)          \n",
    "    affix=word.split(stem_word)[-1]\n",
    "    return affix\n",
    "\n",
    "def is_capitalised(word):\n",
    "    return word[0].upper() == word[0]\n",
    "\n",
    "def all_capital(word):\n",
    "    return word.upper() == word\n",
    "\n",
    "def all_lower(word):\n",
    "    return word.lower() == word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEMM_metrics():\n",
    "    \n",
    "    def __init__(self, test_actual_tags, test_predicted_tags):\n",
    "        '''\n",
    "        The test_actual_tags contains actual tags for the above setences.\n",
    "        The test_predicted_tags contains predicted tags for the test data.\n",
    "        '''\n",
    "        self.counter_dict = defaultdict(lambda: defaultdict(lambda:0))\n",
    "        self.test_actual_tags = test_actual_tags\n",
    "        self.test_predicted_tags = test_predicted_tags\n",
    "        self.tag_metrics = defaultdict(lambda: defaultdict(lambda:0))\n",
    "            \n",
    "    def calc_tag_metrics(self):\n",
    "        '''\n",
    "        Calculate the per-POS accuracy for all the tags in the tag-set\n",
    "        '''\n",
    "        counter_dict = defaultdict(lambda: defaultdict(lambda:0))\n",
    "        \n",
    "        for i in range(len(self.test_actual_tags)):\n",
    "            \n",
    "            if(self.test_actual_tags[i] == self.test_predicted_tags[i]):\n",
    "                counter_dict[self.test_actual_tags[i]]['TP'] += 1\n",
    "            else:\n",
    "                counter_dict[self.test_actual_tags[i]]['FN']    += 1\n",
    "                counter_dict[self.test_predicted_tags[i]]['FP'] += 1\n",
    "        \n",
    "        \n",
    "        for tag in counter_dict.keys():\n",
    "            try:\n",
    "                self.tag_metrics[tag]['Precision'] = counter_dict[tag]['TP']/(counter_dict[tag]['TP']+counter_dict[tag]['FP'])\n",
    "                self.tag_metrics[tag]['Recall'] = counter_dict[tag]['TP']/(counter_dict[tag]['TP']+counter_dict[tag]['FN'])\n",
    "                self.tag_metrics[tag]['F1_score'] = 2*(self.tag_metrics[tag]['Precision']*self.tag_metrics[tag]['Recall'])/(self.tag_metrics[tag]['Precision']+self.tag_metrics[tag]['Recall'])\n",
    "\n",
    "            except ZeroDivisionError:\n",
    "                continue               \n",
    "        self.counter_dict =  counter_dict\n",
    "        \n",
    "    def generate_confusion_matrix(self):\n",
    "        '''\n",
    "        Generate confusion matrix for the particular fold\n",
    "        '''\n",
    "        CM = ConfusionMatrix(self.test_actual_tags ,self.test_predicted_tags)\n",
    "        print(CM)\n",
    "        \n",
    "    def accuracy(self):\n",
    "        '''\n",
    "        Calculate average accuracy score\n",
    "        '''\n",
    "        TP =0\n",
    "        FP =0\n",
    "        for tag in self.counter_dict.keys():\n",
    "            if (tag !='O'):\n",
    "                TP += self.counter_dict[tag]['TP']\n",
    "                FP += self.counter_dict[tag]['FP']\n",
    "        \n",
    "        return TP/(TP+FP)\n",
    "        \n",
    "        \n",
    "    def print_sample(self):\n",
    "        '''\n",
    "        Prints a sample of n = 5 actual and predicted tagged sentences for reference\n",
    "        '''\n",
    "        for i in range(5):\n",
    "            print(\"Actual :\",self.test_actual_tags[i])\n",
    "            print(\"Predicted :\",self.test_predicted_tags[i])\n",
    "        \n",
    "    def get_tag_metrics(self):\n",
    "        '''\n",
    "        Prints the per POS precision,recall and F1 score of predicted tags\n",
    "        '''\n",
    "        \n",
    "        print (\"{:<10} {:<10} {:<10} {:<10}\".format('TAG', 'PRECISION', 'RECALL','F1_SCORE'))\n",
    "        \n",
    "        for key in self.tag_metrics.keys():\n",
    "            precision = str(round(self.tag_metrics[key]['Precision'], 2))\n",
    "            recall    = str(round(self.tag_metrics[key]['Recall'], 2))\n",
    "            F1_score  = str(round(self.tag_metrics[key]['F1_score'], 2))\n",
    "            print (\"{:<10} {:<10} {:<10} {:<10} \".format(key, precision,recall,F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reading data into data frame\n",
    "'''\n",
    "df_train = pd.read_csv('train.txt', sep=\" \",header=None,skip_blank_lines=False, names=['word','POS_tag','Chunk_tag'])\n",
    "df_test = pd.read_csv('test.txt', sep=\" \",header=None,skip_blank_lines=False, names=['word','POS_tag','Chunk_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initial pre-processing\n",
    "'''\n",
    "df_train['Chunk_tag'] = df_train['Chunk_tag'].str.split(\"-\", n = 1, expand = True) \n",
    "df_test['Chunk_tag']  = df_test['Chunk_tag'].str.split(\"-\", n = 1, expand = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Adding extra row for train sentences for ease of processing\n",
    "'''\n",
    "df_train = pd.concat([pd.DataFrame([['EOS','EOS','O']],columns=df_train.columns),df_train],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generating features for MEMM\n",
    "'''\n",
    "\n",
    "df_train['prev_POS']= df_train['POS_tag'].shift(1)\n",
    "df_train['prev_prev_POS']= df_train['POS_tag'].shift(2)\n",
    "df_train['prev_word']= df_train['word'].shift(1)\n",
    "df_train['prev_chunk_tag']= df_train['Chunk_tag'].shift(1)\n",
    "df_train['prev_chunk_tag'] = df_train['prev_chunk_tag'].fillna('O')\n",
    "df_train['Chunk_tag'] = df_train['Chunk_tag'].fillna('O')\n",
    "df_train['next_POS']= df_train['POS_tag'].shift(-1)\n",
    "df_train['next_next_POS']= df_train['POS_tag'].shift(-2)\n",
    "df_train['stemmed_word'] = df_train['word'].apply(stemmer.stem)\n",
    "df_train['all_capital'] = df_train['word'].apply(all_capital)\n",
    "df_train['word_affix'] = df_train['word'].apply(return_affix)\n",
    "df_train = df_train.fillna('EOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Seggregating train data into X and Y\n",
    "'''\n",
    "\n",
    "df_X_train = df_train.drop(columns='Chunk_tag')\n",
    "df_Y_train = df_train['Chunk_tag']\n",
    "\n",
    "df_X_train.head(60)\n",
    "#df_Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (60 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.167\n",
      "             2          -0.43251        0.913\n",
      "             3          -0.28038        0.937\n",
      "             4          -0.21754        0.941\n",
      "             5          -0.18416        0.944\n",
      "             6          -0.16356        0.946\n",
      "             7          -0.14955        0.948\n",
      "             8          -0.13933        0.950\n",
      "             9          -0.13151        0.951\n",
      "            10          -0.12528        0.953\n",
      "            11          -0.12016        0.954\n",
      "            12          -0.11586        0.955\n",
      "            13          -0.11217        0.956\n",
      "            14          -0.10896        0.957\n",
      "            15          -0.10613        0.958\n",
      "            16          -0.10360        0.959\n",
      "            17          -0.10133        0.959\n",
      "            18          -0.09926        0.960\n",
      "            19          -0.09737        0.961\n",
      "            20          -0.09564        0.961\n",
      "            21          -0.09404        0.962\n",
      "            22          -0.09255        0.963\n",
      "            23          -0.09116        0.963\n",
      "            24          -0.08987        0.964\n",
      "            25          -0.08865        0.964\n",
      "            26          -0.08751        0.964\n",
      "            27          -0.08643        0.965\n",
      "            28          -0.08541        0.965\n",
      "            29          -0.08444        0.965\n",
      "            30          -0.08353        0.966\n",
      "            31          -0.08266        0.966\n",
      "            32          -0.08183        0.966\n",
      "            33          -0.08103        0.966\n",
      "            34          -0.08028        0.967\n",
      "            35          -0.07955        0.967\n",
      "            36          -0.07886        0.967\n",
      "            37          -0.07820        0.967\n",
      "            38          -0.07756        0.967\n",
      "            39          -0.07694        0.968\n",
      "            40          -0.07635        0.968\n",
      "            41          -0.07578        0.968\n",
      "            42          -0.07524        0.968\n",
      "            43          -0.07471        0.968\n",
      "            44          -0.07420        0.969\n",
      "            45          -0.07370        0.969\n",
      "            46          -0.07322        0.969\n",
      "            47          -0.07276        0.969\n",
      "            48          -0.07231        0.969\n",
      "            49          -0.07188        0.969\n",
      "            50          -0.07146        0.969\n",
      "            51          -0.07105        0.969\n",
      "            52          -0.07065        0.969\n",
      "            53          -0.07027        0.970\n",
      "            54          -0.06989        0.970\n",
      "            55          -0.06953        0.970\n",
      "            56          -0.06917        0.970\n",
      "            57          -0.06883        0.970\n",
      "            58          -0.06849        0.970\n",
      "            59          -0.06817        0.970\n",
      "         Final          -0.06785        0.970\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Training the MEMM Classifier on the set of features\n",
    "'''\n",
    "dic =df_X_train.to_dict('records')\n",
    "feat =  [(dic[i],df_Y_train[i])for i in range(len(dic))]\n",
    "maxent_classifier = MaxentClassifier.train(feat, max_iter=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dividing the test dataframe to a list of dataframes for each sentence \n",
    "'''\n",
    "idx = [-1]+ df_test.index[df_test.isnull().all(1)].tolist() + [df_test.shape[0]]\n",
    "list_of_test_dfs = [df_test.iloc[idx[n]+1:idx[n+1]] for n in range(len(idx)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Adding relevent features as done in train and seggregating data (X) and Chunk tag (Y) values \n",
    "'''\n",
    "test_sent_X =[]\n",
    "test_sent_Y =[]\n",
    "for dfz in list_of_test_dfs:\n",
    "    dfk = pd.concat([pd.DataFrame([['EOS','EOS','O']],columns=dfz.columns),dfz],ignore_index=True)\n",
    "    dfk = dfk.append(pd.DataFrame(([['EOS','EOS','O']]),columns=dfk.columns),ignore_index=True)\n",
    "    dfk['prev_POS']= dfk['POS_tag'].shift(1)\n",
    "    dfk['prev_prev_POS']= dfk['POS_tag'].shift(2)\n",
    "    dfk['prev_word']= dfk['word'].shift(1)\n",
    "    dfk['stemmed_word'] = dfk['word'].apply(stemmer.stem)\n",
    "    dfk['word_affix'] = dfk['word'].apply(return_affix)\n",
    "    dfk['all_capital'] = dfk['word'].apply(all_capital)\n",
    "    dfk['next_POS']= dfk['POS_tag'].shift(-1)\n",
    "    dfk['next_next_POS']= dfk['POS_tag'].shift(-2)\n",
    "    dfk = dfk.fillna('EOS')\n",
    "    df_test_X = dfk.drop(columns='Chunk_tag')\n",
    "    df_test_Y= dfk['Chunk_tag']\n",
    "    test_sent_X.append(df_test_X)\n",
    "    test_sent_Y.append(df_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_one_pass(test_sent):\n",
    "        '''\n",
    "        Viterbi Algorithm applied to one sentence and corresponding states\n",
    "        Modified from HMM POS \n",
    "        '''\n",
    "        prob_state ={}\n",
    "        sent_dict = test_sent.to_dict('records') #Converting test_Sent dataframe to dictionary\n",
    "        initial_prob_added =  False\n",
    "        # Storing initial probabilities for start of sentences first\n",
    "        \n",
    "        possible_tags = ['B','I','O']\n",
    "        prob_state[1] = {}\n",
    "        for tag in possible_tags:\n",
    "            try:\n",
    "                sent_dict[1]['prev_chunk_tag']='O'\n",
    "                prob = maxent_classifier.prob_classify(sent_dict[1])\n",
    "                if(tag=='I'):\n",
    "                    prob_state[1][tag] = ['O',0]\n",
    "                else:\n",
    "                    prob_state[1][tag] = ['O',float(prob.prob(tag))]\n",
    "            except KeyError: \n",
    "                print(\"error\")\n",
    "                                \n",
    "        # Iterating through the rest of the sentence\n",
    "        max_in_current_level =0\n",
    "        for k in range(2,len(sent_dict)):\n",
    "            prob_state[k] = {}\n",
    "            prev_state  = list(prob_state[k-1].keys()) \n",
    "            curr_state  =  ['B','I','O']\n",
    "            for tag in curr_state:                             \n",
    "                all_states = []\n",
    "                for pt in prev_state: \n",
    "                    sent_dict[k]['prev_chunk_tag']= prev_state[max_in_current_level]\n",
    "                    prob = maxent_classifier.prob_classify(sent_dict[k])\n",
    "                    if(tag == 'I') and (pt == 'O'):\n",
    "                        all_states.append((prob_state[k-1][pt][1])*0.0000000001)\n",
    "                    else:\n",
    "                        all_states.append((prob_state[k-1][pt][1])*float(prob.prob(tag)))\n",
    "                max_in_current_level = all_states.index(max(all_states))\n",
    "                prob_state[k][tag]=[prev_state[max_in_current_level],max(all_states)] #Stores the index as well as the tag seq with max probability\n",
    "                \n",
    "                \n",
    "        # Back tracing to get the predicted tag sequence\n",
    "        \n",
    "        tags = ['O']\n",
    "        for itr in reversed(range(len(sent_dict))):\n",
    "            if(itr>0):\n",
    "                tags.append(prob_state[itr][tags[len(tags)-1]][0])\n",
    "        \n",
    "        tag_list = list(reversed(tags))\n",
    "        return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test on one sentence\n",
    "'''\n",
    "k = viterbi_one_pass(test_sent_X[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(test_sequence):\n",
    "    '''\n",
    "    Viterbi Algorithm applied on test data\n",
    "    '''\n",
    "    predicted_tags = []\n",
    "    predicted_tags_list =[]\n",
    "    for i in range(len(test_sequence)):\n",
    "        tag_seq = viterbi_one_pass(test_sequence[i])\n",
    "        predicted_tags_list.append(tag_seq)\n",
    "        predicted_tags.extend(tag_seq)\n",
    "    return predicted_tags,predicted_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Applying viterbi algorithm to get the predicted tags & \n",
    "Setting the actual tags in a proper format\n",
    "'''\n",
    "predicted_tags,predicted_tags_list = viterbi(test_sent_X)\n",
    "actual_tags = []\n",
    "for data in test_sent_Y:\n",
    "    actual = data.values.tolist()\n",
    "    actual_tags.extend(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG        PRECISION  RECALL     F1_SCORE  \n",
      "O          0.97       0.97       0.97       \n",
      "B          0.95       0.95       0.95       \n",
      "I          0.93       0.93       0.93       \n",
      "  |     B     I     O |\n",
      "--+-------------------+\n",
      "B |<22737> 1043    72 |\n",
      "I |  1052<16056>  237 |\n",
      "O |    98   209 <9899>|\n",
      "--+-------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.16919529069062"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Calculating Tag metrics\n",
    "'''\n",
    "metrics = MEMM_metrics(actual_tags,predicted_tags)\n",
    "metrics.calc_tag_metrics()\n",
    "metrics.get_tag_metrics()\n",
    "metrics.generate_confusion_matrix()\n",
    "metrics.accuracy()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.62x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Heap map output\n",
    "'''\n",
    "\n",
    "cf_matrix = confusion_matrix(actual_tags,predicted_tags)\n",
    "#print(sns.heatmap(cf_matrix/np.sum(cf_matrix),xticklabels=['B', 'I','O'], yticklabels=['B','I','O'], annot=True,fmt='.2%', cmap='Blues'))\n",
    "print(sns.heatmap(cf_matrix, annot=True,xticklabels=['B', 'I','O'], yticklabels=['B','I','O'],fmt=\"d\", cmap='Blues'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dumping the data for further analysis\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('MEMM_actual_tags.pkl', 'wb') as f:\n",
    "    pickle.dump(actual_tags, f)\n",
    "    \n",
    "with open('MEMM_predicted_tags.pkl', 'wb') as f:\n",
    "    pickle.dump(predicted_tags, f)  \n",
    "    \n",
    "with open('MEMM_test_X.pkl', 'wb') as f:\n",
    "    pickle.dump(test_sent_X, f)\n",
    "    \n",
    "with open('MEMM_test_Y.pkl', 'wb') as f:\n",
    "    pickle.dump(test_sent_Y, f)\n",
    "    \n",
    "with open('MEMM_test_Y_pred.pkl', 'wb') as f:\n",
    "    pickle.dump(predicted_tags_list, f)   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
